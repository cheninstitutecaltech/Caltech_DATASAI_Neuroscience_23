{"cells":[{"cell_type":"markdown","metadata":{"id":"IMoQeh0FuNAg"},"source":["# Accessing today's data\n","\n","We will be working with one recording from Frank Lanfranchi's work. Even though this particular recording session lasted only one hour, it comprises more than 75 GB of raw data, and even more preprocessed intermediate results. Fortunately, you don't need to download the entire thing. Instead, you can access it through Google Drive. Please visit:\n","\n","https://drive.google.com/drive/folders/13kbcg5sIaoP7D8tltuypPDlaiFL00MqL\n","\n","Create a shortcut to our data inside your own Google drive by clicking on \"datasai-daw\" (near the top of the window) and on \"Add Shortcut to Drive\".\n","\n","Once you have the data on your Drive, it is straightforward to access it in Colab:"]},{"cell_type":"markdown","metadata":{},"source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cheninstitutecaltech/Caltech_DATASAI_Neuroscience_23/blob/main/07_13_23_day4_adapting_preprocessing_data/code/diy_notebooks/colab/DataSAI_Wagenaar_Raw_traces.ipynb)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eT9eAq8wYcm"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!ls /content/drive/MyDrive/datasai-daw"]},{"cell_type":"markdown","metadata":{"id":"Pd8suQL5y8JQ"},"source":["Your browser will ask for your permission to allow Colab to access your Drive.\n","\n","All of today's data lives inside:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hklObb93yNKa"},"outputs":[],"source":["root = \"/content/drive/MyDrive/datasai-daw/data/2021-07-20_11-59-01\""]},{"cell_type":"markdown","metadata":{"id":"cj0dGPVQzw8T"},"source":["We will begin our exploration today by attaching the raw data to memory using a library written by Frank and me. We first need to install this library on your Colab instance:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jeFsq_hi0GYb"},"outputs":[],"source":["!pip install ephysio"]},{"cell_type":"markdown","metadata":{"id":"ehoJnTxU0JLj"},"source":["Then import the relevant part of the library into your actual notebook workspace:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9u8XiGI0Oj7"},"outputs":[],"source":["from ephysio import openEphysIO"]},{"cell_type":"markdown","metadata":{"id":"uxoFS8e60XY9"},"source":["After those preliminaries, we can access the recording in our notebook:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pYwTQqhG0w0K"},"outputs":[],"source":["oe = openEphysIO.Loader(root)"]},{"cell_type":"markdown","metadata":{"id":"HgTXhW5x17Tt"},"source":["This recording comprises one \"spike stream\", i.e., raw electrode voltage data from all the electrodes:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7KWvjgd042u"},"outputs":[],"source":["oe.spikestreams()"]},{"cell_type":"markdown","metadata":{"id":"xdjnkphC2AHW"},"source":["and one \"nidaq stream\", which contains lots of metadata, such as timestamps of various events occurring during the recording, such as when stimuli were presented:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bsJpaItM2zvJ"},"outputs":[],"source":["oe.nidaqstreams()"]},{"cell_type":"markdown","metadata":{"id":"KUVKzMTw3CMR"},"source":["For the moment, we will take a look only at the raw ephys data.\n","\n","It is unfortunately important to keep in mind that the day's data gathering comprised one \"experiment\" comprising multiple recordings, only one of which I uploaded to the Googledrive:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R52fKRLH3PQl"},"outputs":[],"source":["oe.experiments()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUENCyZW3blA"},"outputs":[],"source":["oe.recordings(expt=1)"]},{"cell_type":"markdown","metadata":{"id":"oJQBTUjj222k"},"source":["Now we can load the data into memory:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Fsgz_EX27Tp"},"outputs":[],"source":["dat = oe.data(oe.spikestream(), expt=1, rec=9)\n","fs_hz = oe.samplingrate(oe.spikestream())"]},{"cell_type":"markdown","metadata":{"id":"fJ5jK7T_3uOL"},"source":["(Actually, we cannot load the data into memory, as it is 75 GB large, but Python conveniently *pretends* the data are loaded, allowing us to access any part of the data as if it all exists in memory.)"]},{"cell_type":"markdown","metadata":{"id":"QfaoRTIL4GrV"},"source":["### Mini-exercise: The shape of the data\n","\n","How many electrodes do we have? How many time points? How many seconds?\n","\n","What is the \"contained\" data type of these data?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WR1Ig8FQ4Oom"},"outputs":[],"source":["# Insert your code here\n"]},{"cell_type":"markdown","metadata":{"id":"ydGmneAJ44eE"},"source":["### Cautionary exercise: The limits of computer memory\n","\n","Let's say you want to know the baseline voltage of one of the electrodes, or its RMS noise level. It is tempting to write:\n","\n","     baseline = np.mean(dat[:, c])\n","     noise = np.std(dat[:, c])\n","\n","after setting *c* to the electrode number you care about. But that won't work, because to calculate that mean, Python would have to read the entire recording into memory. (It is not smart enough to work in chunks, and in any case, even reading through 75 GB of data on a Google drive takes a long time.)\n","\n","Much better to calculate the baseline and noise on a small snippet, or a few small snippets.\n","\n","Do all of the electrodes have a similar baseline voltage? (I.e., is the spread between baselines across electrodes greater than the noise level of individual electrodes?) How much does the noise vary between electrodes? Is the baseline in the first second of data different from the baseline 1 minute later?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18G0gvjJ66ZH"},"outputs":[],"source":["# Insert your code here\n"]},{"cell_type":"markdown","metadata":{"id":"9_uIUWfM69Tu"},"source":["What are the units of your answers? Remember that we worked on completely raw data from the DAQ. If you want an answer in volts, use the function `oe.bitvolts`. Educate yourself about it by running"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvRMUulk7SJ-"},"outputs":[],"source":["oe.bitvolts?"]},{"cell_type":"markdown","metadata":{"id":"RX8tu7_cdxWe"},"source":["Would it be a good idea to convert your raw data to microvolts, e.g., with\n","\n","    dat_uV = dat * oe.bitvolts()\n","\n","Why (not)?"]},{"cell_type":"markdown","metadata":{"id":"LiaIXEBH8rVa"},"source":["### Quick aside on documentation\n","\n","Some code libraries are very well documented online. Others less so. When frustrated, you can ask about all the functions provided by a Python class by way of its `__dict__` attribute, for instance:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FmFp6ZPp88mK"},"outputs":[],"source":["openEphysIO.Loader.__dict__.keys()"]},{"cell_type":"markdown","metadata":{"id":"DzsgLIKP9K53"},"source":["The result is not very easy to read, but at least you get a list of keywords you can then type into a search engine or query in your notebook:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PQqdEmX9PCq"},"outputs":[],"source":["openEphysIO.Loader.nidaqevents?"]},{"cell_type":"markdown","metadata":{"id":"KkqStHSU-RKX"},"source":["By convention, functions that start with \"_\" are not meant for external use. Avoid them unless you really know what you are doing."]},{"cell_type":"markdown","metadata":{"id":"OZaioH9RaNnH"},"source":["## Visualizing raw traces\n","\n","Several libraries exist for visualizing electrophysiology traces. I had a hard time getting any to work in Colab. (Let me know if you fare better!) So I wrote a tiny little visualizer myself using Dash and Plotly. It's so basic that it may even be a usable example to see how this sort of thing is done."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuWf1z-VanWx"},"outputs":[],"source":["!pip install dash\n","from ephysio import vizly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QDJEPngg_13y"},"outputs":[],"source":["app = vizly.Vizly(dat, fs_hz)\n","app.run()"]},{"cell_type":"markdown","metadata":{"id":"pI5dAWu9eYN8"},"source":["### Exercise: Can you see the action potentials?\n","\n","Scroll around the recording a little bit to get a feel for the kind of signals these electrodes pick up."]},{"cell_type":"markdown","metadata":{"id":"p9MysjkNfM5k"},"source":["## Stimulus artifacts\n","\n","Extracellular recordings like these are very prone to electrical artifacts. Generally, a lot of care must be taken to avoid interference from nearby electronics, and even the lights in the room. One form of interference that is very hard to completely prevent, is crosstalk from probes that are used to electrically stimulate the same brain that you are recording from.\n","\n","The recording we are working with today also contains such artifacts. Electrical stimuli were applied at:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHjtZ2_vgR6L"},"outputs":[],"source":["tstim_s = oe.nidaqevents(oe.spikestream(), rec=9)[2][:,0] / fs_hz"]},{"cell_type":"markdown","metadata":{"id":"bZfyUq6aggPS"},"source":["(Sorry for the obscure code; the `[2]` is because the times of stimuli are recorded as TTL pulses on BNC connector #2; the `[:,0]` is because we only care about the start of each pulse.)\n","\n","Let's tell Vizly about our stimulus times:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Y0jGCmVimWR"},"outputs":[],"source":["app = vizly.Vizly(dat, fs_hz, tstim_s)\n","app.run()"]},{"cell_type":"markdown","metadata":{"id":"W6YmWfpbjbLa"},"source":["### Exercise: Artifacts and neuronal responses\n","\n","Do you see the artifacts? Do any neurons respond to the electrical stimuli?"]},{"cell_type":"markdown","metadata":{"id":"fTmZjK99kJiI"},"source":["### Artifact removal\n","\n","Because the electric artifacts are so large compared to the spikes, you cannot expect good results from spike sorting without first taking care of the artifacts. This is a very technical subject, so we're not going into it here. We use an algorithm called SALPA (Wagenaar et al., 2002) that (1) zeroes out parts of traces that are polluted with unrecoverable artifacts and (2) reconstructs signals polluted by lower-amplitude, lower-frequency artifacts.\n","\n","Running SALPA on Colab is a little bit cumbersome, so we'll use precomputed results today:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NcTrfZI9mVC6"},"outputs":[],"source":["dat_pp = oe.data(oe.spikestream(), rec=9, stage=\"salpa\")"]},{"cell_type":"markdown","metadata":{"id":"PJhtZngdm1En"},"source":["(I use the suffix `_pp` to label this variable as processed raw data.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBrh1eahm_2b"},"outputs":[],"source":["app1 = vizly.Vizly(dat_pp, fs_hz, tstim_s)\n","app1.run()"]},{"cell_type":"markdown","metadata":{"id":"1JcoBUNlnx1l"},"source":["### Exercise: Does this look OK?\n","\n","Do you think SALPA did a good job suppressing the artifacts? Do you think a smarter algorithm could reconstruct more of the data, so we could see responses that occur sooner after the stimulus? Create plots overlaying original and cleaned versions of a couple of electrode traces around a few stimuli."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npWHA59bvlyF"},"outputs":[],"source":["# Insert your code here\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNGzwEVYNajkE+L0i4tzMh0","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
