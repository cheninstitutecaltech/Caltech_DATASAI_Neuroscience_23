{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cheninstitutecaltech/Caltech_DATASAI_Neuroscience_23/blob/main/07_20_23_day9_causal_modeling/code/diy_notebooks/exercise1.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal structure discovery: Y structure\n",
    "Authors: Iman Wahle and Frederick Eberhardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will generate synthetic data from a hand-constructed \n",
    "model and use the PC algorithm to infer the underlying model. Since we know\n",
    "the true underlying model in this case, we will confirm that the method returns\n",
    "the correct causal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context('notebook')\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # for making subplots with colorbars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'estimate_parameters.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colab setup\n",
    "!pip install -q corner gdown causal-learn\n",
    "import gdown\n",
    "gdown.download(\"https://drive.google.com/uc?export=view&id=1jxir2Cz-_IKtPuBH0ZonRR4ZN0uwCDnf\",\n",
    "               \"estimate_parameters.py\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to generate data with the following causal structure: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![exercise1_model.png](https://drive.google.com/uc?export=view&id=1FYLNXLKw5hVHrpg0dPK9elOa6U9Yu3ZN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, write a function `generate_data` that takes `n_samples` as an\n",
    "argument. The data for variables $A$, $B$, $C$, and $D$ should be generated as follows:\n",
    "\n",
    "- $A = \\varepsilon_A$, where $\\varepsilon_A \\sim \\mathcal{N}(0,1)$ \n",
    "- $B = \\varepsilon_B$, where $\\varepsilon_B \\sim \\mathcal{N}(0,1)$ \n",
    "- $C = aA + bB + \\varepsilon_C$, where $\\varepsilon_C \\sim \\mathcal{N}(0,1)$ \n",
    "- $D = cC + \\varepsilon_D$, where $\\varepsilon_D \\sim \\mathcal{N}(0,1)$ \n",
    "\n",
    "$a$, $b$, and $c$ are constants you can set to whatever you like.\n",
    "\n",
    "Once the samples have been generated, z-score the data so that each variable\n",
    "has a mean of 0 and standard deviation of 1. \n",
    "\n",
    "The function should return:\n",
    "\n",
    "  - `data`: an `n_samples` x 4 numpy array where each column corresponds to\n",
    "    z-scored samples of $A$, $B$, $C$, and $D$.\n",
    "  - `var_names` : a list of variable names \n",
    "\n",
    "Finally, use your function to generate 5000 samples from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples=5000):\n",
    "    \n",
    "    # add code here\n",
    "    \n",
    "    pass\n",
    "    \n",
    "\n",
    "data, var_names = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin the analysis, it is important to make sure the data matches\n",
    "our expectations:\n",
    "\n",
    "1. Print out the shape of the data and the names of the variables included\n",
    "2. Construct a [corner plot](https://corner.readthedocs.io/en/latest/pages/quickstart/)\n",
    "   of the variable distributions\n",
    "3. Plot the correlation (not covariance) matrix over the four variables\n",
    "4. Plot the inverse of the correlation matrix (aka the \"precision matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out data shape and variable names\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a corner plot of the four variables (make sure to include variable name \n",
    "# labels!)\n",
    "# hint: to control the size of the figure, you can construct a plt.figure object\n",
    "# and pass it in to the corner function as the fig argument\n",
    "\n",
    "from corner import corner\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation matrix between the four variables (make sure to include \n",
    "# variable name labels!). Set the diagonal terms to 0 so that we can focus \n",
    "# on the relationships between variables.\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which entries do we expect to be zero/nonzero in the correlation matrix? \n",
    "Confirm that is the case in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision matrix between the four variables (make sure to include \n",
    "# variable name labels!). Set the diagonal terms to 0 so that we can focus \n",
    "# on the relationships between variables. \n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which entries do we expect to be zero/nonzero in the precision matrix? \n",
    "Confirm that is the case in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the PC algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed that our data looks as we expect, we are ready to \n",
    "use the PC algorithm to infer the causal graph that gave rise to this data.\n",
    "\n",
    "As a reminder, the PC algorithm:\n",
    "\n",
    "1. starts with a fully undirected graph, \n",
    "2. deletes edges between pairs of independent nodes, \n",
    "3. deletes edges between pairs nodes that are independent when a set of \n",
    "   other nodes are conditioned on\n",
    "4. orients colliders: for any set of nodes X-Y-Z where X and Z are not connected,\n",
    "   if Y is not in the conditioning set that makes X and Z conditionally \n",
    "   independent then X-->Y<--Z\n",
    "5. orient any other edges that have a clear orientation given that no other\n",
    "   colliders should be introduced to the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- [Image source](https://towardsdatascience.com/causal-discovery-6858f9af6dcb) -->\n",
    "\n",
    "Today, we will be using the \n",
    "[`causal-learn` package](https://causal-learn.readthedocs.io/en/latest/search_methods_index/Constraint-based%20causal%20discovery%20methods/PC.html) \n",
    "implementation of the PC algorithm. To use this method, we need to set two\n",
    "parameters:\n",
    "\n",
    "- `alpha` : this is our p-value threshold for which the function considers two\n",
    "  variables to be independent \n",
    "- `indep_test` : the type of independence test to use \n",
    "\n",
    "We will set a variable `cg` equal to the output of the `pc` function called on \n",
    "the dataset generated above with `alpha=0.05` and `indep_test='fisherz'` to start. \n",
    "Feel free to come back later and try different values for these arguments to \n",
    "see how they change the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the PC algorithm to our data\n",
    "\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "\n",
    "cg = pc(data, alpha=0.05, indep_test='fisherz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the inferred graph using cg.draw_pydot_graph\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "cg.draw_pydot_graph(labels=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though the PC algorithm generally returns a partially directed\n",
    "graph, all edges in the graph found above are indeed directed. Why is this the \n",
    "case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the inferred graph in matrix representation (which is much\n",
    "easier to understand as the number of variables increases). The matrix \n",
    "representation of the partially directed acyclic graph (PDAG) found by the PC\n",
    "algorithm can be accessed at `cg.G.graph`. The `causal-learn` package \n",
    "represents a PDAG with matrix `G` in the following way:\n",
    "\n",
    "- `G[i,j] = 1` means nodes `i` and `j` are connected with an arrow pointing at `i`\n",
    "- `G[i,j] = -1` means nodes `i` and `j` are connected with a tail ending at `i`\n",
    "- `G[i,j] = 0` means nodes `i` and `j` are not connected\n",
    "\n",
    "Use `plt.imshow` to view this matrix. Make sure to include \n",
    "variable labels and to set an appropriate colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize PDAG matrix representation found by algorithm\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at the adjacency matrix as well (which does not contain any information\n",
    "about edge orientation), convert the matrix representation of the PDAG so that\n",
    "if there's an edge between nodes `i` and `j`, then `adj_mat[i,j] = 1` and\n",
    "`adj_mat[j,i] = 1`. Visualize this matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PDAG matrix to adjacency matrix\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate edge weights and correlation matrix from inferred graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an inferred graph over our variables, we want to see what\n",
    "correlation matrix we would expect from such a graph and how it compares to \n",
    "the correlation matrix computed from our original data. To compute this\n",
    "correlation matrix, we must first estimate edge weights over the graph.\n",
    "\n",
    "Normally, if the PC algorithm had only returned a PDAG, we would need to \n",
    "convert this to a fully directed acyclic graph (DAG) in order to estimate edge \n",
    "weights (this can be any DAG in the equivalence class described by the PDAG). \n",
    "In this case, we can skip this step since we already have a DAG.\n",
    "\n",
    "With this DAG, we can then take each node $j$ in the graph,\n",
    "find all of its parent nodes $p \\in P_j$, and learn weights $\\textbf{b}$ such that \n",
    "$j = \\textbf{b}_1*p_1 + \\textbf{b}_2*p_2 + ... + \\textbf{b}_k*p_k$, approximately holds.\n",
    "\n",
    "We can also calculate the sum of squared residuals between $j$ and our estimate:\n",
    " $r_j^2 = ||j - \\textbf{b}_1*p_1 + \\textbf{b}_2*p_2 + ... + \\textbf{b}_k*p_k||_2$ to \n",
    " get the error on each node $j$.\n",
    "\n",
    "Applying these computations to every node $j$ in the graph, we can construct a\n",
    "matrix $B$ where $B_{ij}$ corresponds to the estimated weight from parent node \n",
    "$i$ to node $j$. We can also construct a diagonal matrix $R$ where \n",
    "$R_{jj} = r_j^2$ as defined above. \n",
    "\n",
    "Use the provided helper function `estimate_parameters` or feel free to write\n",
    "your own code calculate $B$ and $R$. `estimate_parameters` should return two\n",
    "variables:\n",
    "- `edge_params` : an `n_nodes` x `n_nodes` matrix where entry `[i,j]` is equal\n",
    "  to the edge weight found from node $i$ to $j$. If there is no edge between $i$ \n",
    "  and $j$, it equals 0.  \n",
    "- `residuals` : an `n_nodes` x `n_nodes` diagonal matrix where entry `[j,j]` is\n",
    "  equal to $r_j^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate edge weights\n",
    "from estimate_parameters import estimate_parameters\n",
    "edge_params, residuals = estimate_parameters(pdag_mat, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting edge parameters and residuals using `plt.imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the estimated weights and residuals compare to the original data \n",
    "generation model? What may explain any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will estimate the correlation matrix for the graph structure\n",
    "and edge weights that we found and compare to the correlation matrix we \n",
    "calculated at the beginning from the actual data. Given the edge weights\n",
    "and residuals found above, the resulting *covariance* matrix is given by: \n",
    "$C = (I-B)^{-1} R (I-B)^{-T}$, where $I$ is the identity matrix, $B$ is the matrix of\n",
    "edge weights between every pair of nodes $(i,j)$, and $R$ is the diagonal matrix of\n",
    "squared residuals.\n",
    "Note that the relationship between correlation and covariance is: \n",
    "$corr_{i,j} = cov_{i,j}/(\\sigma_i\\sigma_j)$, so each entry $(i,j)$ in the \n",
    "estimated covariance should be normalized by $\\sigma_i\\sigma_j$.\n",
    "\n",
    "Write a function `get_correlation_matrix` that implements the above to\n",
    "return the estimated correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimate_parameters import get_correlation_matrix\n",
    "\n",
    "est_corr = get_correlation_matrix(edge_params, residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the estimated correlation matrix (zero out the diagonal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantify how closely the estimated correlation matrix matches that found\n",
    "from the data. To do this, vectorize the lower-triangular elements in the true\n",
    "and estimated matrices and compute the Pearson correlation between the two vectors.\n",
    "\n",
    "`np.corrcoef` and `np.tril_indices` may be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
